{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu repo görsel üreten bir gan modelini ele alır (vanilla)\n",
    "Bu repo üzerinde 2 aşamada conditional tabular data için veri üretiyor olacağız\n",
    "* Koşullu yapma\n",
    "* Tabular datada çalışıyor hale getirme\n",
    "\n",
    "Şu anda 1. aşamada çalışılınıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import PIL \n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from gan.networks import Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./gan/datasets/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_image, train_labels), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image.reshape(train_image.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# belirli bir koşul için veri seti hazırlama (koşul \"= 5\" olması)\n",
    "indices = np.where(train_labels == 5)[0]\n",
    "train_images_5 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if i in indices:\n",
    "        train_images_5.append(train_images[i])\n",
    "        \n",
    "train_images_5 = np.array(train_images_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images_5).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toplamda 60.000 görsel var\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toplamda 5421 adet \"5\" görseli var\n",
    "train_images_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki model oluşturma adımında hangi koşul yazılırsa yazılsın model gerçek veya sahte ayrımı yapmaya çalışacaktır.\n",
    "Bu yüzden önemli nokta veri setini ayrıştırıp ona vermektir örneğin sadece 5 için görsel çizdirmeye çalışalım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, output):\n",
    "    return keras.losses.BinaryCrossentropy(from_logits=True)(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney\n",
    "# ilk deney koşula uygun n adet yani birden fazla sentetik veri üretebilir miyiz?\n",
    "# ikinci deney farklı koşullar için tekrar ve tekrar model eğitmek ile tek bir model eğitmek arasında ne gibi maliyet farkı var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "num_images = 49\n",
    "random_latent_vectors = tf.random.normal(shape=(num_images, latent_dim))\n",
    "generated_images = generator(random_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# vanilla gan tüm veriler ile eğitiliyor.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 dk 46 saniye - 60000x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for spec in range(10):\n",
    "    indices = np.where(train_labels == spec)[0]\n",
    "    train_images_spec = []\n",
    "    for i in range(len(train_labels)):\n",
    "        if i in indices:\n",
    "            train_images_spec.append(train_images[i])\n",
    "\n",
    "    train_images_spec = np.array(train_images_spec)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images_spec).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    print(\"for spec:\", spec)\n",
    "    print(\"len train_images_spec:\", len(train_images_spec))\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 dk - her veri ayrı ayrı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aşarısı sadece modellerin çıktısını test etmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "list_img = []\n",
    "for spec in range(10):\n",
    "    indices = np.where(train_labels == spec)[0]\n",
    "    train_images_spec = []\n",
    "    for i in range(len(train_labels)):\n",
    "        if i in indices:\n",
    "            train_images_spec.append(train_images[i])\n",
    "\n",
    "    train_images_spec = np.array(train_images_spec)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images_spec).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    print(\"spec:\", spec)\n",
    "    print(\"len train_images_spec:\", len(train_images_spec))\n",
    "    print(\"ilk on:\", indices[:10])\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(train_dataset, epochs=20)\n",
    "    noise = tf.random.normal([1, 100])\n",
    "    generated_image = generator(noise)\n",
    "    list_img.append(generated_image[0, :, :, 0])\n",
    "    #plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(list_img[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: Şu anda ilk aşama tamamlandı. Yani görsel veriler için belirli bir koşula uygun veri üretimi vanilla gan kullanılarak gerçekleştirildi.\n",
    "\n",
    "Birden fazla örnek oluşturma veya oluşturulan örneklerin gösterilmesi ile ilgili bir problem gözlemlenmedi.\n",
    "\n",
    "Ayrıca modellerin tek tek eğitilmesi veya tüm verilerin aynı anda koşuldan bağımsız eğitilmesi konusunda bir zaman farkı bulunmamaktadır.\n",
    "\n",
    "Bizim verilerimizin çok fazla boyuta sahip olduğu için bu kadar uzun sürdü eğitimler örneğin, adult veri seti 32.500x15 boyutundadır, bizim görsel veri setimiz 60.000x48x48 yani yaklaşık 96 katı boyutunda.\n",
    "\n",
    "Burada bir sonraki aşama tabular data için eğitim gerçekleştirebilmektir.\n",
    "Daha sonrasında işlemlerin fonksiyonlaştırılması ve nesneye yönelimli programlama yapısında py dosyası formatına getirilmesidir.\n",
    "\n",
    "En sonunda da bu modelin eğitimi hızlandırılmaya çalışılabilir. Veriyi temsil eden en iyi bir örneklem seçilebilir vs. veya paralelleştirme denenebilir. Modelin içine koşul verilmeye çalışılabilir. Early stopping eklenebilir. Veri boyutuna bağlı epoch sayısı belirlenebilir. Fakat version 1 için elde çalışan bir yapının bulunması iyi olacaktır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şu anda 2. aşamadayız yani görsel verisi için eğittiğimiz modeli tabular data için eğiteceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import PIL \n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from gan.networks import Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/kalybeai-dxlc693/Desktop/GANS/adult.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "for i in ['workclass','education','marital.status','occupation','relationship','race','sex','native.country','income']:\n",
    "    df[i] = le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>77053</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>132870</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>186061</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>140359</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>264663</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>310152</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education.num  marital.status  \\\n",
       "0       90          0   77053         11              9               6   \n",
       "1       82          4  132870         11              9               6   \n",
       "2       66          0  186061         15             10               6   \n",
       "3       54          4  140359          5              4               0   \n",
       "4       41          4  264663         15             10               5   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "32556   22          4  310152         15             10               4   \n",
       "32557   27          4  257302          7             12               2   \n",
       "32558   40          4  154374         11              9               2   \n",
       "32559   58          4  151910         11              9               6   \n",
       "32560   22          4  201490         11              9               4   \n",
       "\n",
       "       occupation  relationship  race  sex  capital.gain  capital.loss  \\\n",
       "0               0             1     4    0             0          4356   \n",
       "1               4             1     4    0             0          4356   \n",
       "2               0             4     2    0             0          4356   \n",
       "3               7             4     4    0             0          3900   \n",
       "4              10             3     4    0             0          3900   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "32556          11             1     4    1             0             0   \n",
       "32557          13             5     4    0             0             0   \n",
       "32558           7             0     4    1             0             0   \n",
       "32559           1             4     4    0             0             0   \n",
       "32560           1             3     4    1             0             0   \n",
       "\n",
       "       hours.per.week  native.country  income  \n",
       "0                  40              39       0  \n",
       "1                  18              39       0  \n",
       "2                  40              39       0  \n",
       "3                  40              39       0  \n",
       "4                  40              39       0  \n",
       "...               ...             ...     ...  \n",
       "32556              40              39       0  \n",
       "32557              38              39       0  \n",
       "32558              40              39       1  \n",
       "32559              40              39       0  \n",
       "32560              20              39       0  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KALYBE~1\\AppData\\Local\\Temp/ipykernel_13708/2975329542.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = scaler.fit_transform(df.drop('income', 1))\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df.drop('income', 1))\n",
    "y_train = df['income'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(X_train)\n",
    "BATCH_SIZE = 32\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, output):\n",
    "    return keras.losses.BinaryCrossentropy(from_logits=True)(labels, output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.float32(X_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vanilla gan tüm veriler ile eğitiliyor.\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalybeai-dxlc693\\anaconda3\\envs\\gpu_tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5016: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "1018/1018 [==============================] - 9s 7ms/step - d_loss: 0.6039 - g_loss: 0.9397\n",
      "Epoch 2/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.5119 - g_loss: 1.1676\n",
      "Epoch 3/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.4118 - g_loss: 1.4352\n",
      "Epoch 4/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3083 - g_loss: 1.8182\n",
      "Epoch 5/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3074 - g_loss: 1.8499\n",
      "Epoch 6/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2884 - g_loss: 1.9946\n",
      "Epoch 7/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2690 - g_loss: 2.1346\n",
      "Epoch 8/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2584 - g_loss: 2.2169\n",
      "Epoch 9/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2395 - g_loss: 2.3396\n",
      "Epoch 10/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2246 - g_loss: 2.4519\n",
      "Epoch 11/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2104 - g_loss: 2.5883\n",
      "Epoch 12/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2045 - g_loss: 2.6710\n",
      "Epoch 13/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2122 - g_loss: 2.5590\n",
      "Epoch 14/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2027 - g_loss: 2.6267\n",
      "Epoch 15/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1964 - g_loss: 2.6919\n",
      "Epoch 16/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1932 - g_loss: 2.7410\n",
      "Epoch 17/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1886 - g_loss: 2.8551\n",
      "Epoch 18/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1856 - g_loss: 2.8413\n",
      "Epoch 19/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1825 - g_loss: 2.8494\n",
      "Epoch 20/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1771 - g_loss: 2.9278\n",
      "Epoch 21/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1732 - g_loss: 2.9815\n",
      "Epoch 22/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1730 - g_loss: 3.0020\n",
      "Epoch 23/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1753 - g_loss: 2.9590\n",
      "Epoch 24/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1763 - g_loss: 2.9310\n",
      "Epoch 25/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1698 - g_loss: 3.0314\n",
      "Epoch 26/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1646 - g_loss: 3.1266: 0s - d_loss: 0.1648 - g_loss: \n",
      "Epoch 27/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1663 - g_loss: 3.0838\n",
      "Epoch 28/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1607 - g_loss: 3.2154\n",
      "Epoch 29/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1564 - g_loss: 3.2411\n",
      "Epoch 30/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1552 - g_loss: 3.2588\n",
      "Epoch 31/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1545 - g_loss: 3.2755\n",
      "Epoch 32/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1554 - g_loss: 3.2801\n",
      "Epoch 33/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1569 - g_loss: 3.2635\n",
      "Epoch 34/50\n",
      "1018/1018 [==============================] - 7s 6ms/step - d_loss: 0.1533 - g_loss: 3.3372\n",
      "Epoch 35/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1499 - g_loss: 3.3707\n",
      "Epoch 36/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1492 - g_loss: 3.3996\n",
      "Epoch 37/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1463 - g_loss: 3.4593\n",
      "Epoch 38/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1478 - g_loss: 3.4214\n",
      "Epoch 39/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1455 - g_loss: 3.4827\n",
      "Epoch 40/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1440 - g_loss: 3.4947\n",
      "Epoch 41/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1449 - g_loss: 3.5339\n",
      "Epoch 42/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1448 - g_loss: 3.5039\n",
      "Epoch 43/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1460 - g_loss: 3.4879\n",
      "Epoch 44/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1456 - g_loss: 3.5006\n",
      "Epoch 45/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1423 - g_loss: 3.5319\n",
      "Epoch 46/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1437 - g_loss: 3.5064\n",
      "Epoch 47/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1397 - g_loss: 3.5520\n",
      "Epoch 48/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1421 - g_loss: 3.5128\n",
      "Epoch 49/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1404 - g_loss: 3.5626\n",
      "Epoch 50/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1399 - g_loss: 3.5721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ce3122d220>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9999978 ,  0.09759989, -0.41890234,  0.16888426, -0.42873618,\n",
       "        1.        ,  0.5243812 ,  0.9686602 ,  0.37340143,  0.7217367 ,\n",
       "       -0.15365264, -0.23727411, -0.00897848,  0.296518  ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(generated_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# önce train içindeki kısım incelenecek\n",
    "# sonra koşula uygun yapılmaya çalışılacaktır\n",
    "# class sayısı dinamik yapılacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
       "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = pd.DataFrame(columns=data.columns[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, workclass, fnlwgt, education, education.num, marital.status, occupation, relationship, race, sex, capital.gain, capital.loss, hours.per.week, native.country, income]\n",
       "Index: []"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "1018/1018 [==============================] - 8s 7ms/step - d_loss: 0.5400 - g_loss: 1.0819\n",
      "Epoch 2/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3344 - g_loss: 1.7635\n",
      "Epoch 3/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3055 - g_loss: 1.7802\n",
      "Epoch 4/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2926 - g_loss: 1.8636\n",
      "Epoch 5/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2738 - g_loss: 2.0141\n",
      "Epoch 6/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2648 - g_loss: 2.0773\n",
      "Epoch 7/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2501 - g_loss: 2.1852\n",
      "Epoch 8/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2357 - g_loss: 2.2981\n",
      "Epoch 9/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2255 - g_loss: 2.3796\n",
      "Epoch 10/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2114 - g_loss: 2.4807\n",
      "Epoch 11/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2065 - g_loss: 2.5256\n",
      "Epoch 12/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2040 - g_loss: 2.5490\n",
      "Epoch 13/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1972 - g_loss: 2.6178\n",
      "Epoch 14/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1935 - g_loss: 2.6665\n",
      "Epoch 15/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1898 - g_loss: 2.7036\n",
      "Epoch 16/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1613 - g_loss: 3.1634\n",
      "Epoch 17/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1733 - g_loss: 2.9842\n",
      "Epoch 18/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1719 - g_loss: 2.9097\n",
      "Epoch 19/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1722 - g_loss: 2.9061\n",
      "Epoch 20/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1697 - g_loss: 2.9313\n",
      "Epoch 21/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1693 - g_loss: 2.9562\n",
      "Epoch 22/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1718 - g_loss: 2.9438\n",
      "Epoch 23/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1704 - g_loss: 2.9849\n",
      "Epoch 24/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1680 - g_loss: 2.9844: 0s - d_loss: 0.1673 - g_\n",
      "Epoch 25/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1693 - g_loss: 2.9519\n",
      "Epoch 26/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1678 - g_loss: 2.9949\n",
      "Epoch 27/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1654 - g_loss: 3.0332\n",
      "Epoch 28/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1670 - g_loss: 2.9779\n",
      "Epoch 29/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1636 - g_loss: 3.0417\n",
      "Epoch 30/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1601 - g_loss: 3.1612\n",
      "Epoch 31/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1561 - g_loss: 3.2827\n",
      "Epoch 32/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1557 - g_loss: 3.2549\n",
      "Epoch 33/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1549 - g_loss: 3.1901\n",
      "Epoch 34/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1534 - g_loss: 3.3438\n",
      "Epoch 35/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1538 - g_loss: 3.2082\n",
      "Epoch 36/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1519 - g_loss: 3.2612\n",
      "Epoch 37/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1524 - g_loss: 3.3945\n",
      "Epoch 38/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1500 - g_loss: 3.2958\n",
      "Epoch 39/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1495 - g_loss: 3.3831\n",
      "Epoch 40/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1473 - g_loss: 3.4470\n",
      "Epoch 41/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1470 - g_loss: 3.3177\n",
      "Epoch 42/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1450 - g_loss: 3.5115\n",
      "Epoch 43/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1470 - g_loss: 3.3502\n",
      "Epoch 44/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1443 - g_loss: 3.5211\n",
      "Epoch 45/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1436 - g_loss: 3.3848\n",
      "Epoch 46/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1422 - g_loss: 3.4256\n",
      "Epoch 47/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1396 - g_loss: 3.5576\n",
      "Epoch 48/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1379 - g_loss: 3.4994\n",
      "Epoch 49/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1342 - g_loss: 3.5983\n",
      "Epoch 50/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.0697 - g_loss: 6.7903\n",
      "Epoch 1/50\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "1018/1018 [==============================] - 7s 6ms/step - d_loss: 0.5331 - g_loss: 1.1027\n",
      "Epoch 2/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.3403 - g_loss: 1.6819\n",
      "Epoch 3/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3123 - g_loss: 1.7553\n",
      "Epoch 4/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2946 - g_loss: 1.8945\n",
      "Epoch 5/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2751 - g_loss: 2.0248\n",
      "Epoch 6/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2582 - g_loss: 2.1398\n",
      "Epoch 7/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2452 - g_loss: 2.2407\n",
      "Epoch 8/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2310 - g_loss: 2.3526\n",
      "Epoch 9/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2209 - g_loss: 2.4436\n",
      "Epoch 10/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2132 - g_loss: 2.5111\n",
      "Epoch 11/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.0952 - g_loss: 4.3906\n",
      "Epoch 12/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1765 - g_loss: 3.2071\n",
      "Epoch 13/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2034 - g_loss: 2.5649\n",
      "Epoch 14/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2029 - g_loss: 2.5470\n",
      "Epoch 15/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1946 - g_loss: 2.6129\n",
      "Epoch 16/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1906 - g_loss: 2.6567\n",
      "Epoch 17/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1909 - g_loss: 2.6701\n",
      "Epoch 18/50\n",
      "1018/1018 [==============================] - 7s 6ms/step - d_loss: 0.1851 - g_loss: 2.7396\n",
      "Epoch 19/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1859 - g_loss: 2.7581\n",
      "Epoch 20/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1798 - g_loss: 2.8105\n",
      "Epoch 21/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1761 - g_loss: 2.8500\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 8s 7ms/step - d_loss: 0.1784 - g_loss: 2.8157\n",
      "Epoch 23/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1750 - g_loss: 2.8486\n",
      "Epoch 24/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1720 - g_loss: 2.9235\n",
      "Epoch 25/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1727 - g_loss: 2.8965\n",
      "Epoch 26/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1720 - g_loss: 2.9103\n",
      "Epoch 27/50\n",
      "1018/1018 [==============================] - 7s 6ms/step - d_loss: 0.1695 - g_loss: 2.9640\n",
      "Epoch 28/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1667 - g_loss: 2.9906\n",
      "Epoch 29/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1603 - g_loss: 3.0897\n",
      "Epoch 30/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1601 - g_loss: 3.0896\n",
      "Epoch 31/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1557 - g_loss: 3.1373\n",
      "Epoch 32/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1615 - g_loss: 3.1313\n",
      "Epoch 33/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1474 - g_loss: 3.5321\n",
      "Epoch 34/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1579 - g_loss: 3.0974\n",
      "Epoch 35/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1531 - g_loss: 3.1454\n",
      "Epoch 36/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1526 - g_loss: 3.1451\n",
      "Epoch 37/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1526 - g_loss: 3.1852\n",
      "Epoch 38/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1509 - g_loss: 3.2270\n",
      "Epoch 39/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1503 - g_loss: 3.2526\n",
      "Epoch 40/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1569 - g_loss: 3.1712\n",
      "Epoch 41/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1451 - g_loss: 3.3193\n",
      "Epoch 42/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1512 - g_loss: 3.2038\n",
      "Epoch 43/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1489 - g_loss: 3.2563\n",
      "Epoch 44/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1476 - g_loss: 3.2666: 0s - d_loss: 0.1\n",
      "Epoch 45/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1494 - g_loss: 3.2966\n",
      "Epoch 46/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1538 - g_loss: 3.2263\n",
      "Epoch 47/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1485 - g_loss: 3.2818\n",
      "Epoch 48/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1468 - g_loss: 3.2972\n",
      "Epoch 49/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1405 - g_loss: 3.4486\n",
      "Epoch 50/50\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1413 - g_loss: 3.3982\n"
     ]
    }
   ],
   "source": [
    "generated_df = pd.DataFrame(columns=data.columns[:])\n",
    "X_train = np.float32(X_train)\n",
    "conditional_datasets = []\n",
    "list_condition = [0, 1]\n",
    "for cond in list_condition:\n",
    "    indices = np.where(y_train == cond)[0]\n",
    "    train_data_cond = []\n",
    "    for i in range(len(y_train)):\n",
    "        if i in indices:\n",
    "            train_data_cond.append(X_train[i])\n",
    "    train_data_cond = np.array(train_data_cond)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    conditional_datasets.append(train_dataset)\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(conditional_datasets[cond], epochs=50)\n",
    "    \n",
    "    num_gen = len(indices)\n",
    "    random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "    generated_data = generator(random_latent_vectors)\n",
    "    gen = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "    gen[data.columns[-1]] = cond\n",
    "    generated_df = pd.concat([generated_df, gen], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.948769</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.754838</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999583</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.101545</td>\n",
       "      <td>0.129699</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.060339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.383098</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.991013</td>\n",
       "      <td>-0.066472</td>\n",
       "      <td>-0.999389</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999321</td>\n",
       "      <td>-0.999996</td>\n",
       "      <td>-0.116576</td>\n",
       "      <td>-0.012319</td>\n",
       "      <td>0.992619</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.654344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.979635</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.996139</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>-0.999482</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.162446</td>\n",
       "      <td>0.148838</td>\n",
       "      <td>-0.999995</td>\n",
       "      <td>0.334584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339175</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>-0.037939</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>-0.991710</td>\n",
       "      <td>-0.999851</td>\n",
       "      <td>-0.170849</td>\n",
       "      <td>-0.077039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.996548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.998225</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.125909</td>\n",
       "      <td>0.343030</td>\n",
       "      <td>-0.996460</td>\n",
       "      <td>0.235007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.055512</td>\n",
       "      <td>0.097827</td>\n",
       "      <td>-0.013413</td>\n",
       "      <td>0.175842</td>\n",
       "      <td>-0.403104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048213</td>\n",
       "      <td>-0.259645</td>\n",
       "      <td>0.403551</td>\n",
       "      <td>0.693283</td>\n",
       "      <td>-0.144101</td>\n",
       "      <td>-0.211437</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.300367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.547526</td>\n",
       "      <td>0.089584</td>\n",
       "      <td>0.317269</td>\n",
       "      <td>0.179078</td>\n",
       "      <td>-0.403339</td>\n",
       "      <td>-0.409997</td>\n",
       "      <td>0.995392</td>\n",
       "      <td>-0.912349</td>\n",
       "      <td>0.394151</td>\n",
       "      <td>0.687365</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>-0.207981</td>\n",
       "      <td>0.038356</td>\n",
       "      <td>0.284578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>-0.997682</td>\n",
       "      <td>0.087117</td>\n",
       "      <td>0.318418</td>\n",
       "      <td>0.173505</td>\n",
       "      <td>-0.398885</td>\n",
       "      <td>-0.409025</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>-0.910195</td>\n",
       "      <td>0.387590</td>\n",
       "      <td>0.689025</td>\n",
       "      <td>-0.142008</td>\n",
       "      <td>-0.210578</td>\n",
       "      <td>-0.024318</td>\n",
       "      <td>0.291520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-0.891580</td>\n",
       "      <td>0.106836</td>\n",
       "      <td>-0.990976</td>\n",
       "      <td>0.187298</td>\n",
       "      <td>-0.412992</td>\n",
       "      <td>-0.411350</td>\n",
       "      <td>-0.858522</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>0.392411</td>\n",
       "      <td>0.688943</td>\n",
       "      <td>-0.143461</td>\n",
       "      <td>-0.203109</td>\n",
       "      <td>-0.012399</td>\n",
       "      <td>0.289575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.234686</td>\n",
       "      <td>0.084332</td>\n",
       "      <td>0.683718</td>\n",
       "      <td>-0.797333</td>\n",
       "      <td>0.700109</td>\n",
       "      <td>-0.430104</td>\n",
       "      <td>-0.505223</td>\n",
       "      <td>-0.934105</td>\n",
       "      <td>0.387680</td>\n",
       "      <td>0.711107</td>\n",
       "      <td>-0.147767</td>\n",
       "      <td>-0.226189</td>\n",
       "      <td>0.398143</td>\n",
       "      <td>0.297018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education.num  \\\n",
       "0      1.000000  -0.948769 -1.000000   1.000000      -0.754838   \n",
       "1      1.000000  -0.383098 -1.000000   0.991013      -0.066472   \n",
       "2      1.000000  -0.654344  1.000000   0.998898       0.979635   \n",
       "3      1.000000   0.339175 -1.000000   0.999990      -0.037939   \n",
       "4      1.000000   0.010208 -1.000000   0.999306       0.996548   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "32556  0.055512   0.097827 -0.013413   0.175842      -0.403104   \n",
       "32557  0.547526   0.089584  0.317269   0.179078      -0.403339   \n",
       "32558 -0.997682   0.087117  0.318418   0.173505      -0.398885   \n",
       "32559 -0.891580   0.106836 -0.990976   0.187298      -0.412992   \n",
       "32560  0.234686   0.084332  0.683718  -0.797333       0.700109   \n",
       "\n",
       "       marital.status  occupation  relationship      race       sex  \\\n",
       "0            0.999666   -1.000000      1.000000 -0.999583 -1.000000   \n",
       "1           -0.999389   -1.000000      1.000000 -0.999321 -0.999996   \n",
       "2            1.000000   -0.996139      0.999994 -0.999482 -1.000000   \n",
       "3           -0.999998    0.999999      0.999949 -0.991710 -0.999851   \n",
       "4            1.000000    0.999999      1.000000 -0.998225 -0.999989   \n",
       "...               ...         ...           ...       ...       ...   \n",
       "32556        1.000000   -0.048213     -0.259645  0.403551  0.693283   \n",
       "32557       -0.409997    0.995392     -0.912349  0.394151  0.687365   \n",
       "32558       -0.409025    0.011728     -0.910195  0.387590  0.689025   \n",
       "32559       -0.411350   -0.858522     -0.894495  0.392411  0.688943   \n",
       "32560       -0.430104   -0.505223     -0.934105  0.387680  0.711107   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week  native.country income  \n",
       "0         -0.101545      0.129699        0.999996        0.060339      0  \n",
       "1         -0.116576     -0.012319        0.992619        0.190698      0  \n",
       "2         -0.162446      0.148838       -0.999995        0.334584      0  \n",
       "3         -0.170849     -0.077039        1.000000        0.259705      0  \n",
       "4         -0.125909      0.343030       -0.996460        0.235007      0  \n",
       "...             ...           ...             ...             ...    ...  \n",
       "32556     -0.144101     -0.211437        0.021732        0.300367      1  \n",
       "32557     -0.145209     -0.207981        0.038356        0.284578      1  \n",
       "32558     -0.142008     -0.210578       -0.024318        0.291520      1  \n",
       "32559     -0.143461     -0.203109       -0.012399        0.289575      1  \n",
       "32560     -0.147767     -0.226189        0.398143        0.297018      1  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "1018/1018 [==============================] - 8s 7ms/step - d_loss: 0.5307 - g_loss: 1.1262\n",
      "Epoch 2/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3802 - g_loss: 1.5279\n",
      "Epoch 3/10\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2954 - g_loss: 1.8628\n",
      "Epoch 4/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2894 - g_loss: 1.9202\n",
      "Epoch 5/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2744 - g_loss: 2.0435\n",
      "Epoch 6/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2590 - g_loss: 2.1822\n",
      "Epoch 7/10\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2467 - g_loss: 2.2302\n",
      "Epoch 8/10\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2228 - g_loss: 2.4003\n",
      "Epoch 9/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.1869 - g_loss: 2.9518\n",
      "Epoch 10/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2224 - g_loss: 2.4475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ce31893b20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_datasets[0]\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(conditional_datasets[0], epochs=10)\n",
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "data: Tensor(\"data:0\", shape=(None, 14), dtype=float32)\n",
      "batch_size: Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "random_latent_vectors: Tensor(\"random_normal:0\", shape=(None, 100), dtype=float32)\n",
      "1018/1018 [==============================] - 8s 7ms/step - d_loss: 0.5404 - g_loss: 1.0693\n",
      "Epoch 2/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3617 - g_loss: 1.6112\n",
      "Epoch 3/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.3121 - g_loss: 1.7945\n",
      "Epoch 4/10\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.3034 - g_loss: 1.8676\n",
      "Epoch 5/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2882 - g_loss: 1.9626\n",
      "Epoch 6/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2727 - g_loss: 2.0534\n",
      "Epoch 7/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2539 - g_loss: 2.1919\n",
      "Epoch 8/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2374 - g_loss: 2.3056\n",
      "Epoch 9/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2284 - g_loss: 2.3698\n",
      "Epoch 10/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - d_loss: 0.2052 - g_loss: 2.5699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ce326a8370>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_datasets[0]\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(conditional_datasets[1], epochs=10)\n",
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen1 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen1[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'income'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education.num',\n",
       "       'marital.status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital.gain', 'capital.loss', 'hours.per.week', 'native.country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
