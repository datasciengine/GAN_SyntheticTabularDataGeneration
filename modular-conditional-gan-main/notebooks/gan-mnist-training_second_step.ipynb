{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu repo görsel üreten bir gan modelini ele alır (vanilla)\n",
    "Bu repo üzerinde 2 aşamada conditional tabular data için veri üretiyor olacağız\n",
    "* Koşullu yapma\n",
    "* Tabular datada çalışıyor hale getirme\n",
    "\n",
    "Şu anda 2. aşamada çalışılınıyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import PIL \n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from gan.networks import Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./gan/datasets/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_image, train_labels), (_, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_image.reshape(train_image.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 32\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# belirli bir koşul için veri seti hazırlama (koşul \"= 5\" olması)\n",
    "indices = np.where(train_labels == 5)[0]\n",
    "train_images_5 = []\n",
    "for i in range(len(train_labels)):\n",
    "    if i in indices:\n",
    "        train_images_5.append(train_images[i])\n",
    "        \n",
    "train_images_5 = np.array(train_images_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images_5).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toplamda 60.000 görsel var\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toplamda 5421 adet \"5\" görseli var\n",
    "train_images_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıdaki model oluşturma adımında hangi koşul yazılırsa yazılsın model gerçek veya sahte ayrımı yapmaya çalışacaktır.\n",
    "Bu yüzden önemli nokta veri setini ayrıştırıp ona vermektir örneğin sadece 5 için görsel çizdirmeye çalışalım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, output):\n",
    "    return keras.losses.BinaryCrossentropy(from_logits=True)(labels, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = discriminator(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney\n",
    "# ilk deney koşula uygun n adet yani birden fazla sentetik veri üretebilir miyiz?\n",
    "# ikinci deney farklı koşullar için tekrar ve tekrar model eğitmek ile tek bir model eğitmek arasında ne gibi maliyet farkı var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "num_images = 49\n",
    "random_latent_vectors = tf.random.normal(shape=(num_images, latent_dim))\n",
    "generated_images = generator(random_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generated_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deney 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# vanilla gan tüm veriler ile eğitiliyor.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 dk 46 saniye - 60000x28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for spec in range(10):\n",
    "    indices = np.where(train_labels == spec)[0]\n",
    "    train_images_spec = []\n",
    "    for i in range(len(train_labels)):\n",
    "        if i in indices:\n",
    "            train_images_spec.append(train_images[i])\n",
    "\n",
    "    train_images_spec = np.array(train_images_spec)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images_spec).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    print(\"for spec:\", spec)\n",
    "    print(\"len train_images_spec:\", len(train_images_spec))\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33 dk - her veri ayrı ayrı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aşarısı sadece modellerin çıktısını test etmek için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "list_img = []\n",
    "for spec in range(10):\n",
    "    indices = np.where(train_labels == spec)[0]\n",
    "    train_images_spec = []\n",
    "    for i in range(len(train_labels)):\n",
    "        if i in indices:\n",
    "            train_images_spec.append(train_images[i])\n",
    "\n",
    "    train_images_spec = np.array(train_images_spec)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images_spec).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    print(\"spec:\", spec)\n",
    "    print(\"len train_images_spec:\", len(train_images_spec))\n",
    "    print(\"ilk on:\", indices[:10])\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(train_dataset, epochs=20)\n",
    "    noise = tf.random.normal([1, 100])\n",
    "    generated_image = generator(noise)\n",
    "    list_img.append(generated_image[0, :, :, 0])\n",
    "    #plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(list_img[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: Şu anda ilk aşama tamamlandı. Yani görsel veriler için belirli bir koşula uygun veri üretimi vanilla gan kullanılarak gerçekleştirildi.\n",
    "\n",
    "Birden fazla örnek oluşturma veya oluşturulan örneklerin gösterilmesi ile ilgili bir problem gözlemlenmedi.\n",
    "\n",
    "Ayrıca modellerin tek tek eğitilmesi veya tüm verilerin aynı anda koşuldan bağımsız eğitilmesi konusunda bir zaman farkı bulunmamaktadır.\n",
    "\n",
    "Bizim verilerimizin çok fazla boyuta sahip olduğu için bu kadar uzun sürdü eğitimler örneğin, adult veri seti 32.500x15 boyutundadır, bizim görsel veri setimiz 60.000x48x48 yani yaklaşık 96 katı boyutunda.\n",
    "\n",
    "Burada bir sonraki aşama tabular data için eğitim gerçekleştirebilmektir.\n",
    "Daha sonrasında işlemlerin fonksiyonlaştırılması ve nesneye yönelimli programlama yapısında py dosyası formatına getirilmesidir.\n",
    "\n",
    "En sonunda da bu modelin eğitimi hızlandırılmaya çalışılabilir. Veriyi temsil eden en iyi bir örneklem seçilebilir vs. veya paralelleştirme denenebilir. Modelin içine koşul verilmeye çalışılabilir. Early stopping eklenebilir. Veri boyutuna bağlı epoch sayısı belirlenebilir. Fakat version 1 için elde çalışan bir yapının bulunması iyi olacaktır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şu anda 2. aşamadayız yani görsel verisi için eğittiğimiz modeli tabular data için eğiteceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras \n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import PIL \n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from gan.networks import Generator, Discriminator, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/kalybeai-dxlc693/Desktop/GANS/adult.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "for i in ['workclass','education','marital.status','occupation','relationship','race','sex','native.country','income']:\n",
    "    df[i] = le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>77053</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>132870</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>186061</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>140359</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>264663</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>310152</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>257302</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>154374</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>151910</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>201490</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  fnlwgt  education  education.num  marital.status  \\\n",
       "0       90          0   77053         11              9               6   \n",
       "1       82          4  132870         11              9               6   \n",
       "2       66          0  186061         15             10               6   \n",
       "3       54          4  140359          5              4               0   \n",
       "4       41          4  264663         15             10               5   \n",
       "...    ...        ...     ...        ...            ...             ...   \n",
       "32556   22          4  310152         15             10               4   \n",
       "32557   27          4  257302          7             12               2   \n",
       "32558   40          4  154374         11              9               2   \n",
       "32559   58          4  151910         11              9               6   \n",
       "32560   22          4  201490         11              9               4   \n",
       "\n",
       "       occupation  relationship  race  sex  capital.gain  capital.loss  \\\n",
       "0               0             1     4    0             0          4356   \n",
       "1               4             1     4    0             0          4356   \n",
       "2               0             4     2    0             0          4356   \n",
       "3               7             4     4    0             0          3900   \n",
       "4              10             3     4    0             0          3900   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "32556          11             1     4    1             0             0   \n",
       "32557          13             5     4    0             0             0   \n",
       "32558           7             0     4    1             0             0   \n",
       "32559           1             4     4    0             0             0   \n",
       "32560           1             3     4    1             0             0   \n",
       "\n",
       "       hours.per.week  native.country  income  \n",
       "0                  40              39       0  \n",
       "1                  18              39       0  \n",
       "2                  40              39       0  \n",
       "3                  40              39       0  \n",
       "4                  40              39       0  \n",
       "...               ...             ...     ...  \n",
       "32556              40              39       0  \n",
       "32557              38              39       0  \n",
       "32558              40              39       1  \n",
       "32559              40              39       0  \n",
       "32560              20              39       0  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KALYBE~1\\AppData\\Local\\Temp/ipykernel_12384/2975329542.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = scaler.fit_transform(df.drop('income', 1))\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(df.drop('income', 1))\n",
    "y_train = df['income'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(X_train)\n",
    "BATCH_SIZE = 32\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, output):\n",
    "    return keras.losses.BinaryCrossentropy(from_logits=True)(labels, output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.float32(X_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# vanilla gan tüm veriler ile eğitiliyor.\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan.fit(train_dataset, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = generator(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(generated_data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# önce train içindeki kısım incelenecek\n",
    "# sonra koşula uygun yapılmaya çalışılacaktır\n",
    "# class sayısı dinamik yapılacak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalybeai-dxlc693\\anaconda3\\envs\\gpu_tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:5016: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 7s 6ms/step - d_loss: 0.5400 - g_loss: 1.0791\n",
      "Epoch 2/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.3405 - g_loss: 1.7054\n",
      "Epoch 3/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.3205 - g_loss: 1.7262\n",
      "Epoch 4/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.3002 - g_loss: 1.8644\n",
      "Epoch 5/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2796 - g_loss: 2.0078\n",
      "Epoch 6/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2642 - g_loss: 2.1109\n",
      "Epoch 7/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2501 - g_loss: 2.2138\n",
      "Epoch 8/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2366 - g_loss: 2.3225\n",
      "Epoch 9/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2253 - g_loss: 2.3902\n",
      "Epoch 10/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.2165 - g_loss: 2.4811\n",
      "Epoch 11/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1758 - g_loss: 2.9614\n",
      "Epoch 12/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.0771 - g_loss: 4.9827\n",
      "Epoch 13/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1966 - g_loss: 2.8141\n",
      "Epoch 14/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1896 - g_loss: 2.8202\n",
      "Epoch 15/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1705 - g_loss: 3.1729\n",
      "Epoch 16/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1932 - g_loss: 2.6873\n",
      "Epoch 17/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1880 - g_loss: 2.7272\n",
      "Epoch 18/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1844 - g_loss: 2.7776\n",
      "Epoch 19/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1834 - g_loss: 2.8063\n",
      "Epoch 20/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1769 - g_loss: 2.9467\n",
      "Epoch 21/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1747 - g_loss: 2.9386\n",
      "Epoch 22/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1563 - g_loss: 3.3361\n",
      "Epoch 23/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1671 - g_loss: 3.1233\n",
      "Epoch 24/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1668 - g_loss: 3.0656\n",
      "Epoch 25/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1674 - g_loss: 2.9547\n",
      "Epoch 26/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1624 - g_loss: 3.0533\n",
      "Epoch 27/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1627 - g_loss: 3.0924\n",
      "Epoch 28/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1611 - g_loss: 3.1081\n",
      "Epoch 29/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1556 - g_loss: 3.1724\n",
      "Epoch 30/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1574 - g_loss: 3.1463\n",
      "Epoch 31/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1534 - g_loss: 3.2197\n",
      "Epoch 32/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1464 - g_loss: 3.4238\n",
      "Epoch 33/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.0279 - g_loss: 7.0080\n",
      "Epoch 34/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -0.0700 - g_loss: 14.1489\n",
      "Epoch 35/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -0.2007 - g_loss: 26.6502\n",
      "Epoch 36/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: -0.3846 - g_loss: 44.8620\n",
      "Epoch 37/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -0.6685 - g_loss: 72.5516\n",
      "Epoch 38/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -1.1576 - g_loss: 119.0108\n",
      "Epoch 39/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -1.9207 - g_loss: 190.9972\n",
      "Epoch 40/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -3.0596 - g_loss: 297.6691\n",
      "Epoch 41/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -4.7437 - g_loss: 453.6678\n",
      "Epoch 42/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -6.6186 - g_loss: 625.9461\n",
      "Epoch 43/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: -9.5104 - g_loss: 881.9551\n",
      "Epoch 44/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -13.3797 - g_loss: 1224.7315\n",
      "Epoch 45/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -17.1840 - g_loss: 1576.4364\n",
      "Epoch 46/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -23.4957 - g_loss: 2147.2331\n",
      "Epoch 47/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -28.7544 - g_loss: 2601.1628\n",
      "Epoch 48/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -36.2983 - g_loss: 3295.1873\n",
      "Epoch 49/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -45.1104 - g_loss: 4044.0546\n",
      "Epoch 50/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: -55.1733 - g_loss: 4958.0104\n",
      "Epoch 1/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.5432 - g_loss: 1.1120\n",
      "Epoch 2/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.3848 - g_loss: 1.5156\n",
      "Epoch 3/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.2894 - g_loss: 1.9332\n",
      "Epoch 4/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.2969 - g_loss: 1.9157\n",
      "Epoch 5/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.2782 - g_loss: 2.0397\n",
      "Epoch 6/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.2548 - g_loss: 2.1971\n",
      "Epoch 7/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.2421 - g_loss: 2.3042\n",
      "Epoch 8/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.2310 - g_loss: 2.3955\n",
      "Epoch 9/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.2195 - g_loss: 2.5142\n",
      "Epoch 10/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.2153 - g_loss: 2.5437\n",
      "Epoch 11/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.2066 - g_loss: 2.6208\n",
      "Epoch 12/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1982 - g_loss: 2.6965\n",
      "Epoch 13/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1918 - g_loss: 2.8050\n",
      "Epoch 14/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1922 - g_loss: 2.8066\n",
      "Epoch 15/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1857 - g_loss: 2.8702\n",
      "Epoch 16/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1825 - g_loss: 2.9373\n",
      "Epoch 17/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1789 - g_loss: 2.9439\n",
      "Epoch 18/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1757 - g_loss: 3.0396\n",
      "Epoch 19/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1714 - g_loss: 3.0976\n",
      "Epoch 20/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1744 - g_loss: 3.0059\n",
      "Epoch 21/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1718 - g_loss: 3.1052\n",
      "Epoch 22/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1688 - g_loss: 3.0921\n",
      "Epoch 23/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.0642 - g_loss: 5.5887\n",
      "Epoch 24/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1482 - g_loss: 3.5266\n",
      "Epoch 25/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1585 - g_loss: 3.2410\n",
      "Epoch 26/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1590 - g_loss: 3.2373\n",
      "Epoch 27/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1582 - g_loss: 3.2709\n",
      "Epoch 28/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1547 - g_loss: 3.3470\n",
      "Epoch 29/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1544 - g_loss: 3.3470\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1520 - g_loss: 3.3761\n",
      "Epoch 31/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1486 - g_loss: 3.4560\n",
      "Epoch 32/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1471 - g_loss: 3.5841\n",
      "Epoch 33/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1490 - g_loss: 3.4335\n",
      "Epoch 34/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1442 - g_loss: 3.6188\n",
      "Epoch 35/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1464 - g_loss: 3.4631\n",
      "Epoch 36/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1444 - g_loss: 3.5157\n",
      "Epoch 37/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1445 - g_loss: 3.5191\n",
      "Epoch 38/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1407 - g_loss: 3.6350\n",
      "Epoch 39/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1454 - g_loss: 3.5562\n",
      "Epoch 40/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1440 - g_loss: 3.5548\n",
      "Epoch 41/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1436 - g_loss: 3.5858\n",
      "Epoch 42/50\n",
      "1018/1018 [==============================] - 6s 5ms/step - d_loss: 0.1430 - g_loss: 3.5702\n",
      "Epoch 43/50\n",
      "1018/1018 [==============================] - 5s 5ms/step - d_loss: 0.1424 - g_loss: 3.5560\n",
      "Epoch 44/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1415 - g_loss: 3.5798\n",
      "Epoch 45/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1412 - g_loss: 3.6020\n",
      "Epoch 46/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1409 - g_loss: 3.6411\n",
      "Epoch 47/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1412 - g_loss: 3.6078\n",
      "Epoch 48/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1420 - g_loss: 3.5675\n",
      "Epoch 49/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1411 - g_loss: 3.6175\n",
      "Epoch 50/50\n",
      "1018/1018 [==============================] - 6s 6ms/step - d_loss: 0.1411 - g_loss: 3.6104\n"
     ]
    }
   ],
   "source": [
    "generated_df = pd.DataFrame(columns=data.columns[:])\n",
    "X_train = np.float32(X_train)\n",
    "conditional_datasets = []\n",
    "list_condition = [0, 1]\n",
    "for cond in list_condition:\n",
    "    indices = np.where(y_train == cond)[0]\n",
    "    train_data_cond = []\n",
    "    for i in range(len(y_train)):\n",
    "        if i in indices:\n",
    "            train_data_cond.append(X_train[i])\n",
    "    train_data_cond = np.array(train_data_cond)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    conditional_datasets.append(train_dataset)\n",
    "    \n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "    gan = GAN(discriminator, generator, latent_dim)\n",
    "    gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "    gan.fit(conditional_datasets[cond], epochs=50)\n",
    "    \n",
    "    num_gen = len(indices)\n",
    "    random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "    generated_data = generator(random_latent_vectors)\n",
    "    gen = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "    gen[data.columns[-1]] = cond\n",
    "    generated_df = pd.concat([generated_df, gen], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953050</td>\n",
       "      <td>0.146762</td>\n",
       "      <td>0.872278</td>\n",
       "      <td>-0.052673</td>\n",
       "      <td>-0.246752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968416</td>\n",
       "      <td>-0.994053</td>\n",
       "      <td>0.939371</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.172806</td>\n",
       "      <td>-0.460047</td>\n",
       "      <td>-0.271497</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.527140</td>\n",
       "      <td>-0.152709</td>\n",
       "      <td>0.998394</td>\n",
       "      <td>-0.887488</td>\n",
       "      <td>-0.985910</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.849285</td>\n",
       "      <td>-0.993623</td>\n",
       "      <td>-0.886467</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.092665</td>\n",
       "      <td>0.163035</td>\n",
       "      <td>-0.495563</td>\n",
       "      <td>-0.786626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.997269</td>\n",
       "      <td>0.290166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.999682</td>\n",
       "      <td>0.996131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.181234</td>\n",
       "      <td>0.849084</td>\n",
       "      <td>-0.924706</td>\n",
       "      <td>-0.692538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966846</td>\n",
       "      <td>0.158713</td>\n",
       "      <td>-0.069453</td>\n",
       "      <td>-0.042285</td>\n",
       "      <td>0.152899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>-0.992939</td>\n",
       "      <td>0.967859</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.256531</td>\n",
       "      <td>-0.589193</td>\n",
       "      <td>-0.297412</td>\n",
       "      <td>0.379283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.335150</td>\n",
       "      <td>0.948862</td>\n",
       "      <td>-0.770063</td>\n",
       "      <td>-0.971274</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999736</td>\n",
       "      <td>-0.967104</td>\n",
       "      <td>-0.648454</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.137781</td>\n",
       "      <td>0.089266</td>\n",
       "      <td>-0.679941</td>\n",
       "      <td>-0.676600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>-0.008087</td>\n",
       "      <td>0.079040</td>\n",
       "      <td>-0.697490</td>\n",
       "      <td>0.182821</td>\n",
       "      <td>-0.416689</td>\n",
       "      <td>-0.388530</td>\n",
       "      <td>-0.031631</td>\n",
       "      <td>-0.901579</td>\n",
       "      <td>0.387564</td>\n",
       "      <td>0.706460</td>\n",
       "      <td>-0.133491</td>\n",
       "      <td>-0.212863</td>\n",
       "      <td>-0.020339</td>\n",
       "      <td>0.283989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>-0.755999</td>\n",
       "      <td>0.087710</td>\n",
       "      <td>-0.939204</td>\n",
       "      <td>0.187991</td>\n",
       "      <td>-0.419922</td>\n",
       "      <td>-0.393651</td>\n",
       "      <td>0.082476</td>\n",
       "      <td>-0.894353</td>\n",
       "      <td>0.389686</td>\n",
       "      <td>0.704007</td>\n",
       "      <td>-0.144048</td>\n",
       "      <td>-0.217244</td>\n",
       "      <td>-0.075433</td>\n",
       "      <td>0.288187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>-0.334042</td>\n",
       "      <td>0.083338</td>\n",
       "      <td>-0.339167</td>\n",
       "      <td>0.187430</td>\n",
       "      <td>-0.411940</td>\n",
       "      <td>-0.397491</td>\n",
       "      <td>-0.299551</td>\n",
       "      <td>-0.899506</td>\n",
       "      <td>0.385305</td>\n",
       "      <td>0.702436</td>\n",
       "      <td>-0.132318</td>\n",
       "      <td>-0.215476</td>\n",
       "      <td>0.880396</td>\n",
       "      <td>0.287024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>-0.904473</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>-0.831591</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>-0.752403</td>\n",
       "      <td>-0.569980</td>\n",
       "      <td>-0.998397</td>\n",
       "      <td>0.108146</td>\n",
       "      <td>0.390841</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>-0.161410</td>\n",
       "      <td>-0.292565</td>\n",
       "      <td>-0.467243</td>\n",
       "      <td>0.307222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>-0.788064</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>-0.658716</td>\n",
       "      <td>0.166186</td>\n",
       "      <td>-0.488750</td>\n",
       "      <td>-0.771214</td>\n",
       "      <td>-0.941187</td>\n",
       "      <td>-0.507509</td>\n",
       "      <td>0.426739</td>\n",
       "      <td>0.715776</td>\n",
       "      <td>-0.153924</td>\n",
       "      <td>-0.244585</td>\n",
       "      <td>0.938841</td>\n",
       "      <td>0.309049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  workclass    fnlwgt  education  education.num  \\\n",
       "0      0.953050   0.146762  0.872278  -0.052673      -0.246752   \n",
       "1      0.527140  -0.152709  0.998394  -0.887488      -0.985910   \n",
       "2     -0.997269   0.290166  1.000000  -0.999682       0.996131   \n",
       "3      0.966846   0.158713 -0.069453  -0.042285       0.152899   \n",
       "4      1.000000  -0.335150  0.948862  -0.770063      -0.971274   \n",
       "...         ...        ...       ...        ...            ...   \n",
       "32556 -0.008087   0.079040 -0.697490   0.182821      -0.416689   \n",
       "32557 -0.755999   0.087710 -0.939204   0.187991      -0.419922   \n",
       "32558 -0.334042   0.083338 -0.339167   0.187430      -0.411940   \n",
       "32559 -0.904473   0.999988 -0.831591   0.008513      -0.752403   \n",
       "32560 -0.788064   0.999954 -0.658716   0.166186      -0.488750   \n",
       "\n",
       "       marital.status  occupation  relationship      race       sex  \\\n",
       "0            1.000000    0.968416     -0.994053  0.939371 -1.000000   \n",
       "1           -1.000000   -0.849285     -0.993623 -0.886467 -1.000000   \n",
       "2            1.000000    1.000000     -1.000000 -0.999989 -1.000000   \n",
       "3            1.000000    0.998999     -0.992939  0.967859 -1.000000   \n",
       "4           -1.000000   -0.999736     -0.967104 -0.648454 -1.000000   \n",
       "...               ...         ...           ...       ...       ...   \n",
       "32556       -0.388530   -0.031631     -0.901579  0.387564  0.706460   \n",
       "32557       -0.393651    0.082476     -0.894353  0.389686  0.704007   \n",
       "32558       -0.397491   -0.299551     -0.899506  0.385305  0.702436   \n",
       "32559       -0.569980   -0.998397      0.108146  0.390841  0.733607   \n",
       "32560       -0.771214   -0.941187     -0.507509  0.426739  0.715776   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week  native.country income  \n",
       "0         -0.172806     -0.460047       -0.271497        0.011720      0  \n",
       "1          0.092665      0.163035       -0.495563       -0.786626      0  \n",
       "2          0.181234      0.849084       -0.924706       -0.692538      0  \n",
       "3         -0.256531     -0.589193       -0.297412        0.379283      0  \n",
       "4          0.137781      0.089266       -0.679941       -0.676600      0  \n",
       "...             ...           ...             ...             ...    ...  \n",
       "32556     -0.133491     -0.212863       -0.020339        0.283989      1  \n",
       "32557     -0.144048     -0.217244       -0.075433        0.288187      1  \n",
       "32558     -0.132318     -0.215476        0.880396        0.287024      1  \n",
       "32559     -0.161410     -0.292565       -0.467243        0.307222      1  \n",
       "32560     -0.153924     -0.244585        0.938841        0.309049      1  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_df.to_csv(\"C:/Users/kalybeai-dxlc693/Desktop/GANS/modular-conditional-gan-main/datasets/output_synt/adult.csv\",\n",
    "              index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KALYBE~1\\AppData\\Local\\Temp/ipykernel_12384/2971949418.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  gen_features = scaler.inverse_transform(generated_df.drop('income', 1))\n"
     ]
    }
   ],
   "source": [
    "gen_features = scaler.inverse_transform(generated_df.drop('income', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df = pd.DataFrame(gen_features, columns=data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df[data.columns[-1]] = generated_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_df.to_csv(\"C:/Users/kalybeai-dxlc693/Desktop/GANS/modular-conditional-gan-main/datasets/output_synt/adult.csv\",\n",
    "              index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conditional_datasets[0]\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(conditional_datasets[0], epochs=10)\n",
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conditional_datasets[0]\n",
    "discriminator = Discriminator()\n",
    "generator = Generator()\n",
    "gan = GAN(discriminator, generator, latent_dim)\n",
    "gan.compile(discriminator_optimizer, generator_optimizer, loss_fn)\n",
    "gan.fit(conditional_datasets[1], epochs=10)\n",
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen1 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen1[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gen = list_count[cond]\n",
    "random_latent_vectors = tf.random.normal(shape=(num_gen, latent_dim))\n",
    "generated_data = generator(random_latent_vectors)\n",
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen0 = pd.DataFrame(np.array(generated_data), columns=data.columns[:-1])\n",
    "gen0[data.columns[-1]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
